---
title: "Accumulation of DCV in flies with and without Wolbachia"
author: "Angelique Asselin"
date: "2023-09-19"
output: html_document
---

# Experimental details
 Virus:     DCV(EB)
 Titre:     10E08 IU/mL 
 Fly:       w1118 wMelPopTet and w1118 wMelPop
 Figure:    1B
 
# Rationale 
To determine if Wolbachia and time have an impact on accumulation of DCV viral RNA in flies. 

# Approach 
Calculate mean normalised expression of DCV RNA genome relative to Drosophila melanogaster house keeping gene RpL32. 
Conduct an ANOVA to see if mean normalised expression of DCV RNA genome is different with Time and Wolbachia

# Preparation
```{r Preparation Loading librarys}
library(tidyverse)
library(car)
library(emmeans)
library(rstatix)
```

# Importing Ct data 
Data
Target_takeoff    = The ct value for reactions targeting DCV 
Reference_takeoff = The ct value for reactions targeting RpL32
Sample_number     = The number of the sample note that samples have two technical replicates 

Data_ID 
Contains information such as the time of collection (Time) for each sample the replicate (Replicate) number(n=6) and the fly line the data are from (Line; 0 = w1118-wMelpopTet, 1= w1118-wMelPop)

```{r Importing Ct Data}
# Importing raw Ct values
data_DCV_acc<- as.data.frame(read_csv("Accumulation_DCV_Figure_1_B_data.csv"))

# Importing sample ID information
data_ID <- as.data.frame(read_csv("Accumulation_DCV_Figure_1_B_data_sample_ID.csv"))
```

# Calculating MNE from Ct Data 
This analysis utilises Equation (2) and (3) from 
DOI: 10.1093/bioinformatics/btg157

```{r Analysing Ct Data}
# Seting the data
Data <- data_DCV_acc

#Sets % SEM cutoff for samples (default 20%)
SEMCutoff = 20

# Do you wish to automatically censor data over the above SEM% threshold? 0 = no, 1 = yes (default yes)
UseCutoff = 1

# Change std Amp. efficiency if necessary
TarAmp = 1.79 # DCV primer efficiency derived previously in the lab 
RefAmp = 1.64 # rpl32 primer efficiency derived previously in the lab  

# Sorting the data for analysis

Normalised <-
  data.frame("Sample", "MNE", "SE of MNE", "SE of MNE as % (x<=20%)")
i = 0
val = 1:nrow(Data)
val <- val[seq(1, (length(val)), 2)]
w = unlist(c(Data[4]))
x = unlist(c(Data[3]))
y = unlist(c(Data[2]))
s = matrix(x, nrow = 1, ncol = nrow(Data))
v = matrix(w, nrow = 1, ncol = nrow(Data))
t = matrix(y, nrow = nrow(Data), ncol = 1)
list <-
  data.frame("Censored Samples", "MNE", "SE of MNE", "SE of MNE as % (x>25%)")

# For loop processes all the data and adds it to the dataframe
for (i in val) {
  # Calculates MNE of Duplicates
  MNE2 = (RefAmp ^ ((v[1, i] + v[1, i + 1]) / 2)) / (TarAmp ^ ((s[1, i] +
                                                                  s[1, i + 1]) / 2))
  
  # Calculates SE of MNE
  SEofCTTAR = sd(c(s[1, i], s[1, i + 1])) / sqrt(2)
  SEofCTREF = sd(c(v[1, i], v[1, i + 1])) / sqrt(2)
  
  SEofMNE = MNE2 * (((log(TarAmp) * SEofCTTAR) ^ 2) + ((log(RefAmp) * SEofCTREF) ^
                                                         2)) ^ .5
  
  # Calculates SE of MNE as %
  SEofMNEasP = (SEofMNE / MNE2) * 100
  
  # Adds each set of data to the data frame (you may wish to change the digits= option to be smaller if you wish)
  if (UseCutoff == 1) {
    if (SEofMNEasP > SEMCutoff) {
      cat(
        "Sample:",
        t[i, 1],
        "was censored due to exceeding SEM cutoff of",
        SEMCutoff,
        "with a value of",
        (round(SEofMNEasP, digits = 2)),
        "\n"
      )
      list[nrow(list) + 1,] = c(
        t[i, 1],
        round(MNE2, digits = 10),
        round(SEofMNE, digits = 5),
        round(SEofMNEasP, digits = 2)
      )
    }
    else {
      Normalised[nrow(Normalised) + 1,] = c(
        t[i, 1],
        round(MNE2, digits = 10),
        round(SEofMNE, digits = 5),
        round(SEofMNEasP, digits = 2)
      )
    }
  }
  else {
    Normalised[nrow(Normalised) + 1,] = c(
      t[i, 1],
      round(MNE2, digits = 10),
      round(SEofMNE, digits = 5),
      round(SEofMNEasP, digits = 2)
    )
  }
}

View(Normalised)

```

```{r Formats MNE output}
# Formats the analysed dataset
MNE <- Normalised %>%
  rename(
    Sample = X.Sample.,
    DCV_MNE = X.MNE.,
    DCV_SE_MNE = X.SE.of.MNE.,
    DCV_SE_Percent = X.SE.of.MNE.as....x..20...
  ) %>%
  slice(-1) %>% 
  select(Sample, everything())

# Visualize the data frame
View(MNE)
```

```{r Censored data }
# Formats the censored data set
SEM_censored <- list %>%
  rename(
    Sample_file = X.Censored.Samples.,
    MNE = X.MNE.,
    SE_MNE = X.SE.of.MNE.,
    SE_Percent = X.SE.of.MNE.as....x.25...
  ) %>%
  mutate(Sample_file = as.character(Sample_file)) %>%
  slice(-1)

# Visualize the data set
SEM_censored # There should be no data censored
```

# Adding information about the samples
Joins the data with the associated Data_ID information

```{r Sample information}
# Ensure consistent format for the sample number
MNE$Sample <- as.double(MNE$Sample)
data_ID$Sample <- as.double(data_ID$Sample)

# Joining the MNE dataframe with the sample ID dataframe 
data_MNE <- full_join(data_ID, MNE, by = join_by(Sample))
```

# Formating MNE for analysis and graphing 

```{r Formating data}
# Coding the factors correctly 
data_MNE$DCV_MNE <- as.numeric(data_MNE$DCV_MNE)

# Log-transforming data
data_MNE <- data_MNE %>% 
  mutate(log_10_DCV_MNE = log10(DCV_MNE)) 

# Sub-setting time points that have full replicates 
data_MNE_sub <- subset(data_MNE, Time != "240") %>% 
  subset( Time != "168") 

# Formatting the data for analysis 
data_anova <- data_MNE_sub %>% 
  select(log_10_DCV_MNE, Time, Line, Replicate, Sample) %>% 
  mutate(Line = as.factor(Line)) %>% 
  mutate(Time = as.factor(Time))
```

# Analysis - ANOVA Rank
The residuals for the ANOVA (See archived code) were not normal therefore the assumptions of the analysis were violated. Analysis was instead conducted on rank transformed data. 

Conover, W.J. and R.L. Iman, R. L. 1981. Rank transformations as a bridge between parametric and nonparametric statistics. American Statistician. 35 (3): 124-129.
https://www.cfholbert.com/blog/nonparametric_two_way_anova/ - Layman explaination


```{r ANOVA on Ranked data}

DCV_rank1 <- aov(rank(log_10_DCV_MNE) ~ 
                  Line * 
                  Time , 
                data = data_anova)

DCV_rank2 <- aov(rank(log_10_DCV_MNE) ~ 
                  Line + 
                  Time , 
                data = data_anova) #Best fit model

DCV_rank3 <- aov(rank(log_10_DCV_MNE) ~ 
                  Time , 
                data = data_anova) 

DCV_rank4 <- aov(rank(log_10_DCV_MNE) ~ 
                  Line , 
                data = data_anova)


# Finding the best fit model
AIC(DCV_rank1, DCV_rank2) 
AIC(DCV_rank2, DCV_rank3)
AIC(DCV_rank2, DCV_rank4)

# Summary of analysis 
summary(DCV_rank1) # Best fit 
```

# Assumptions - ANOVA Rank

1. Homogeneity of variances (PASS)
2. Normality (PASS)
3. Outliers (PASS)

As the interaction between Wolbachia and time is significant, it is difficult to interpret multiple comparisons of the different times therefore didn't conduct any as it would not add anything. 

```{r Assessing ANOVA Rank Assumptions}
# Visually Check 
plot(DCV_rank1)

# Extract residuals and fitted values
DCV_rank1_fitted <- fitted(DCV_rank1)
DCV_rank1_res <- residuals(DCV_rank1)

# 1. Homogeneity of variances
plot(DCV_rank1, 1)
leveneTest(log_10_DCV_MNE ~ 
             Line , 
           data = data_anova)

# 2. Normality
plot(DCV_rank1, 2)

# Run Shapiro-Wilk test on residuals
shapiro_test(residuals(DCV_rank1))

# 3. Outliers 
plot(DCV_rank1, 1)
outlierTest(DCV_rank1) # No outliers
```

```{r Interactions}

# Computes estimated marginal means for factor combos
emmeans(DCV_rank1, pairwise ~ Time | Line)

# Tells at which time points MNE of DCV is different between flies
em_out_category <- emmeans(DCV_rank1,  ~ Line | Time) 

em_summary <- 
em_out_category %>% 
  pairs() %>% 
  test(joint = TRUE)

# Output
print(em_out_category) # Means at each timepoint
print(em_summary) # Summary of which times Wol has an impact
pairs(em_out_category) # More detailed analyss of time Wolbachia has an impact

```


# Graphing results 
```{r Graphing results}

# Converting Time back into appropriate
data_anova$Time <- as.character(data_anova$Time)
data_anova$Time <- as.double(data_anova$Time)

# Creating plot object
DCV_plot <-ggplot(data_anova) +
  geom_jitter(
    aes(Time, log_10_DCV_MNE, col = Line),
    size = 6,
    position = position_jitter(width = 0.01),
    show.legend = FALSE
  ) +
  geom_smooth(aes(Time, log_10_DCV_MNE, group = Line, col = Line), show.legend = FALSE, inherit.aes = FALSE, method = 'loess', span = 1) +
  scale_color_manual(values = c("black", "red")) +
  scale_fill_manual(values = c("black", "red")) +  # Specify the fill colors for Line = 0 and Line = 1
  theme_classic() +
  scale_x_continuous(breaks = unique(data_anova$Time), labels = unique(data_anova$Time)) + # set time axis to correspond to actual time points
  labs(x = "Time (hours)",
       y = expression(bold(
         "Relative levels of DCV RNA"
       ))) +
  theme(
    plot.margin = unit(c(3, 1, 1, 2), "lines"),
    axis.title = element_text(
      size = 30,
      face = "bold",
      colour = "black"
    ),
    axis.title.y = element_text(
      size = 30,
      face = "bold",
      colour = "black",
      hjust = 0.5,
      vjust = 0.1
    ),
    axis.text = element_text(
      size = 30,
      face = "bold",
      colour = "black"
    ),
    plot.title = element_text(size = 30)
  ) +
  guides(fill = FALSE, colour = FALSE)

```

```{r Exporting Output (Run outside of RMD)}
# Exporting stats output
sink("Accumulation_DCV_Figure_1_B_stats_output_anova.txt") # change file name
summary(DCV_rank1) # prints coxme output to txt file UP TO HERE
sink() # closes the connection **CRITICAL**

sink("Accumulation_DCV_Figure_1_B_stats_output_anova_call.txt") # change file name
print(DCV_rank1) # prints coxme output to txt file UP TO HERE
sink() # closes the connection **CRITICAL**

# Exporting interaction summary 
sink("Accumulation_DCV_Figure_1_B_stats_output_emmean_means.txt") # change file name
print(em_out_category) # Means at each timepoint
sink() # closes the connection **CRITICAL**

# Exporting Summary of the times at which Wol has an impact
sink("Accumulation_DCV_Figure_1_B_stats_output_emmean_summary.txt") # change file name
print(em_summary) # Summary of which times Wol has an impact
sink() # closes the connection **CRITICAL**

# Exporting Summary of the times at which Wol has an impact
sink("Accumulation_DCV_Figure_1_B_stats_output_emmean_summary_detailed.txt") # change file name
pairs(em_out_category) # More detailed analyss of time Wolbachia has an impact
sink() # closes the connection **CRITICAL**

# Exporting figure
today <- Sys.Date()
date <- format(today, format = "%y%m%d")
name <- paste(date, "Figure", "1", "B",  sep = "_")
pdf_name <- paste(name, "pdf", sep = ".")
ggsave(filename = pdf_name,
       plot = DCV_plot, 
       width = 15, 
       height = 7.5)

```

# ARCHIVED (initial ANOVA analysis)
# Analysis - ANOVA 

Comparing more than two groups
1. Two way ANOVA (un-paired)

# Results - ANOVA
Residuals are non-normally distributed if using the log10 mean normalised expression data. Therefore see ANOVA Rank analysis 

```{r ANOVA Fitting the model}

# Fitting the model 
DCV_aov1 <- aov(log_10_DCV_MNE ~ 
                  Line * 
                  Time , 
                data = data_anova)

DCV_aov2 <- aov(log_10_DCV_MNE ~ 
                  Line + 
                  Time , 
                data = data_anova) #Best fit model

DCV_aov3 <- aov(log_10_DCV_MNE ~ 
                  Time , 
                data = data_anova) 

DCV_aov4 <- aov(log_10_DCV_MNE ~ 
                  Line , 
                data = data_anova)


# Finding the best fit model
AIC(DCV_aov1, DCV_aov2) 
AIC(DCV_aov2, DCV_aov3)
AIC(DCV_aov2, DCV_aov4)


# Summary of analysis 
summary(DCV_aov1) # Best fit 

# Summary statistics
require("dplyr")
group_by(data_anova, Line, Time) %>%
  summarise(
    count = n(),
    mean = mean(log_10_DCV_MNE, na.rm = TRUE),
    sd = sd(log_10_DCV_MNE, na.rm = TRUE)
  )
```
```{r ANOVA Multiple comparisons}
# Multiple comparisons 
TukeyHSD(DCV_aov1,
         which = "Time")
```

# Assumptions -ANOVA initial FAIL
1. Homogeneity of variances (PASS)
2. Normality (FAIL)
3. Outliers (PASS)

```{r ANOVA Assumptions}

# Visually Check 
plot(DCV_aov1)

# Extract residuals and fitted values
DCV_aov1_fitted <- fitted(DCV_aov1)
DCV_aov1_res <- residuals(DCV_aov1)

# 1. Homogeneity of variances
plot(DCV_aov1, 1)
leveneTest(log_10_DCV_MNE ~ 
                  Line , 
                data = data_anova)

# 2. Normality
plot(DCV_aov1, 2)

# Run Shapiro-Wilk test on residuals
shapiro_test(residuals(DCV_aov1))

# 3. Outliers 
plot(DCV_aov1, 1)
outlierTest(DCV_aov1) # No outliers
```


